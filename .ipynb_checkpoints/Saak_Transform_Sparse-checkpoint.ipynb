{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from math import log\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import product\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import *\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "import copy\n",
    "from skimage.transform import resize\n",
    "from skimage.util import *\n",
    "\n",
    "#load MNIST\n",
    "(X_train_raw, y_train_raw), (X_test_raw, y_test_raw) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "code_folding": [
     0,
     16,
     25,
     40,
     64,
     81,
     86,
     114,
     121,
     128,
     135,
     147,
     157,
     169,
     177,
     189
    ]
   },
   "outputs": [],
   "source": [
    "def image_set_preprocessing(X, y, batch_ratio = 1, pad_size=2, pad_method='constant'):\n",
    "    X_pad = np.pad(X, ((0,0),(pad_size,pad_size),(pad_size,pad_size)), 'constant')\n",
    "    \n",
    "    batch_size = (int)(X_pad.shape[0]*batch_ratio)\n",
    "    \n",
    "    order = np.array(range(X_pad.shape[0]))\n",
    "    np.random.shuffle(order)\n",
    "    X_pad_shuffle = X_pad[order]\n",
    "    y_shuffle = y[order]\n",
    "\n",
    "    X_train_batch = ((X_pad_shuffle[0:batch_size, :, :]).astype('float32'))/255\n",
    "    y_train_batch = y_shuffle[0:batch_size,]\n",
    "    X_train_batch = X_train_batch.reshape(X_train_batch.shape[0], X_train_batch.shape[1], X_train_batch.shape[2], 1)\n",
    "    \n",
    "    return X_train_batch, y_train_batch\n",
    "\n",
    "def flatten_patches(cubio, size):\n",
    "    window_shape = (1,size,size,cubio.shape[3])\n",
    "    step = (1,size,size,cubio.shape[3])\n",
    "    patches = view_as_windows(cubio, window_shape, step)\n",
    "    patches = patches.squeeze(axis = (3,4))\n",
    "    patches_panel = patches.reshape(-1, patches.shape[-3]*patches.shape[-2]*patches.shape[-1])\n",
    "    \n",
    "    return patches_panel\n",
    "\n",
    "def flatten_patches_v2(cubio):\n",
    "    window_shape = (1,2,2,cubio.shape[3])\n",
    "    step = (1,2,2,cubio.shape[3])\n",
    "    patches = view_as_windows(cubio, window_shape, step)\n",
    "    patches = patches.squeeze(axis = (3,4))\n",
    "    patches_panel = patches.reshape(-1, patches.shape[-3]*patches.shape[-2]*patches.shape[-1])\n",
    "    \n",
    "    return patches_panel\n",
    "\n",
    "def remove_low_variance(patches_panel,thr=0.05):\n",
    "    std = np.std(patches_panel, axis = 1)\n",
    "    patches_clean = patches_panel[std>thr]\n",
    "    \n",
    "    return patches_clean\n",
    "\n",
    "def remove_patches_mean(patches):\n",
    "    mean = patches.mean(axis = 1)\n",
    "    patches_mean_remov = (patches.T-mean).T\n",
    "    \n",
    "    return patches_mean_remov\n",
    "\n",
    "def pca_kernel(patches, n_comps, kernel):\n",
    "    pca = PCA(n_components = n_comps)\n",
    "    pca.fit(patches)\n",
    "    kernel.append(pca)  \n",
    "    \n",
    "def pca_transform(kernel, layer, patches_mean_remov, patches_panel, X_train):\n",
    "    n_sample = X_train.shape[0]\n",
    "    h = (int)(X_train.shape[1]/pow(2,layer))\n",
    "    patches_proj = k[layer-1].transform(patches_mean_remov)\n",
    "    cubio_pos = patches_proj.reshape(n_sample,h,h,-1)\n",
    "    cubio_neg = -cubio_pos\n",
    "    cubio_pca = np.concatenate((cubio_pos, cubio_neg), axis=3)\n",
    "    dc = patches_panel.mean(axis=1)*2\n",
    "    dc = dc.reshape(n_sample, h, h, -1)\n",
    "    cubio_next = np.concatenate((cubio_pca, dc), axis=3)\n",
    "    \n",
    "    return cubio_next\n",
    "\n",
    "def dc_add(X_train, layer, cubio, cubio_pca):\n",
    "    n_sample = 60000\n",
    "    cubio_enlarge = np.zeros((n_sample,32*pow(2,1),32*pow(2,1),cubio.shape[3]))\n",
    "    for i in range(n_sample):\n",
    "        cubio_enlarge[i,:,:,:] = resize(cubio[i,:,:,:], output_shape=[cubio.shape[1]*2,cubio.shape[2]*2,cubio.shape[3]])\n",
    "    window_shape = (1,2,2,cubio_enlarge.shape[3])\n",
    "    step = (1,2,2,cubio_enlarge.shape[3])\n",
    "    patches = view_as_windows(cubio_enlarge, window_shape, step)\n",
    "    patches = patches.squeeze(axis = (3,4))\n",
    "    patches_panel = patches.reshape(-1, patches.shape[-3]*patches.shape[-2]*patches.shape[-1])\n",
    "\n",
    "    dc = patches_panel.mean(axis=1)*2\n",
    "    dc = dc.reshape(n_sample, 32, 32, -1)\n",
    "    cubio_next = np.concatenate((cubio_pca, dc), axis=3)\n",
    "    \n",
    "    return cubio_next\n",
    "\n",
    "def relu(cubio):\n",
    "    cubio_relu = cubio * (cubio > 0)\n",
    "    \n",
    "    return cubio_relu\n",
    "     \n",
    "def one_stage_training(layer, n_comps, kernel, feature_list, X):\n",
    "    print(\"training at the %dth layer ...\" %(layer))\n",
    "    patches_panel = flatten_patches(X, pow(2,layer))\n",
    "    patches_mean_remov = remove_patches_mean(patches_panel)\n",
    "    if layer == 1:\n",
    "        patches_clean = remove_low_variance(patches_mean_remov)\n",
    "    else:\n",
    "        patches_clean = patches_mean_remov\n",
    "    pca_kernel(patches_clean, n_comps[layer-1], k)\n",
    "    cubio_next = relu(pca_transform(k, layer, patches_mean_remov, patches_panel, X_train))\n",
    "    feature_list.append(cubio_next)\n",
    "    print(\"Done! the shape of output cubio is %s.\" %(cubio_next.shape,))\n",
    "    \n",
    "def one_stage_training_v2(cubio, layer, n_comps, kernel, feature_list, X):\n",
    "    print(\"training at the %dth layer ...\" %(layer))\n",
    "    patches_panel = flatten_patches_v2(cubio)\n",
    "    patches_mean_remov = remove_patches_mean(patches_panel)\n",
    "    if layer == 1:\n",
    "        patches_clean = remove_low_variance(patches_mean_remov)\n",
    "    else:\n",
    "        patches_clean = patches_mean_remov\n",
    "    pca_kernel(patches_clean,n_comps[layer-1], kernel)\n",
    "    cubio_next = relu(pca_transform(kernel, layer, patches_mean_remov, patches_panel, X))\n",
    "    feature_list.append(cubio_next)\n",
    "    print(\"Done! the shape of output cubio is %s.\" %(cubio_next.shape,))\n",
    "    \n",
    "    return cubio_next\n",
    "\n",
    "def feature_fusion(feature_list, num_layers):\n",
    "    feature = feature_list[0].reshape(feature_list[0].shape[0], -1)\n",
    "    for i in range(num_layers-1):\n",
    "        feature = np.concatenate((feature,feature_list[i+1].reshape(feature_list[i+1].shape[0], -1)), axis=1)\n",
    "    print(\"the shape of features we get is %s.\" %(feature.shape,))\n",
    "    return feature\n",
    "\n",
    "def Reduce_Feature(n_comps, feature):\n",
    "    pca = PCA(n_components = n_comps)\n",
    "    X_pc = pca.fit_transform(feature)\n",
    "    print(\"the number of dimensions kept is %d.\" %(X_pc.shape[1]))\n",
    "    \n",
    "    return X_pc, pca\n",
    "\n",
    "def F_test(percent, feature, label):\n",
    "    Ftest = SelectPercentile(chi2, percent)\n",
    "    X_f = Ftest.fit_transform(feature, label)\n",
    "    print(\"the number of feature dimensions passing F-test is %d.\" %(X_f.shape[1]))\n",
    "\n",
    "    return X_f, Ftest\n",
    "    \n",
    "def SVM_training(feature, label, n_comps, percent):\n",
    "    print('SVM is under training...')\n",
    "    X_f, Ftest = F_test(percent, feature, label)\n",
    "    X_pc, pca = Reduce_Feature(n_comps, X_f)\n",
    "    clf = SVC()\n",
    "    clf.fit(X_pc, label)\n",
    "    y_pred = clf.predict(X_pc)\n",
    "    accuracy = accuracy_score(label, y_pred)\n",
    "    print(\"SVM accuracy on training sample is %f\" %(accuracy))\n",
    "    \n",
    "    return Ftest, pca, clf, accuracy\n",
    "\n",
    "def SVM_training_v2(X_pc, label):\n",
    "    print('SVM is under training...')\n",
    "    clf = SVC()\n",
    "    clf.fit(X_pc, label)\n",
    "    y_pred = clf.predict(X_pc)\n",
    "    accuracy = accuracy_score(label, y_pred)\n",
    "    print(\"SVM accuracy on training sample is %f\" %(accuracy))\n",
    "    \n",
    "    return clf, accuracy\n",
    "\n",
    "def RF_training(feature, label, n_comps, percent):\n",
    "    print('Random Forest is under training...')\n",
    "    X_f, Ftest = F_test(percent, feature, label)\n",
    "    X_pc, pca = Reduce_Feature(n_comps, X_f)\n",
    "    clf = RandomForestClassifier()  \n",
    "    clf.fit(X_pc, label)\n",
    "    y_pred = clf.predict(X_pc)\n",
    "    accuracy = accuracy_score(label, y_pred)\n",
    "    print(\"RF accuracy on training sample is %f\" %(accuracy))\n",
    "    \n",
    "    return Ftest, pca, clf, accuracy\n",
    "\n",
    "def one_stage_testing(layer, kernel, feature_list, X):\n",
    "    print(\"training at the %dth layer ...\" %(layer))\n",
    "    patches_panel = flatten_patches(X, pow(2,layer))\n",
    "    patches_mean_remov = remove_patches_mean(patches_panel)\n",
    "    cubio_next = relu(pca_transform(kernel, layer, patches_mean_remov, patches_panel, X))\n",
    "    feature_list.append(cubio_next)\n",
    "    print(\"Done! the shape of output cubio is %s.\" %(cubio_next.shape,))\n",
    "\n",
    "def RF_testing(feature, label, Ftest, pca, clf):\n",
    "    print(\"Test smaples are under Random Forest's testing...\")\n",
    "    feature_test = Ftest.transform(feature)\n",
    "    print(\"the number of feature dimensions passing F-test is %d.\" %(feature_test.shape[1]))\n",
    "    feature_pca = pca.transform(feature_test)\n",
    "    print(\"the number of dimensions kept is %d.\" %(feature_pca.shape[1]))\n",
    "    y_pred = clf.predict(feature_pca)\n",
    "    accuracy = accuracy_score(label, y_pred)     \n",
    "    print(\"RF accuracy on test sample is %f\" %(accuracy))\n",
    "    \n",
    "    return accuracy, y_pred\n",
    "          \n",
    "def SVM_testing(feature, label, Ftest, pca, clf):\n",
    "    print(\"Test smaples are under SVM's testing...\")\n",
    "    feature_test = Ftest.transform(feature)\n",
    "    print(\"the number of feature dimensions passing F-test is %d.\" %(feature_test.shape[1]))\n",
    "    feature_pca = pca.transform(feature_test)\n",
    "    print(\"the number of dimensions kept is %d.\" %(feature_pca.shape[1]))\n",
    "    y_pred = clf.predict(feature_pca)\n",
    "    accuracy = accuracy_score(label, y_pred)     \n",
    "    print(\"SVM accuracy on test sample is %f\" %(accuracy))\n",
    "    \n",
    "    return accuracy, y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the first version -- parallel structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#prepare training parameters list\n",
    "k = []\n",
    "k_means = []\n",
    "\n",
    "feature_list = []\n",
    "n_comps = [3, 4, 7, 6, 8]\n",
    "\n",
    "#preprocess input image batch and label batch\n",
    "X_train, y_train_batch = image_set_preprocessing(X_train_raw, y_train_raw, batch_ratio = 1)\n",
    "cubio = copy.deepcopy(X_train)\n",
    "\n",
    "#compute the number of layers\n",
    "layer_cnt = (int)(log(X_train.shape[1])/log(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### the first stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cubio_1 = flatten_patches(cubio, 2)\n",
    "\n",
    "cubio_1_remov = remove_patches_mean(cubio_1)\n",
    "\n",
    "cubio_1_clean = remove_low_variance(cubio_1_remov,thr=0.05)\n",
    "\n",
    "PCA_obj = []\n",
    "k.append(PCA_obj)\n",
    "\n",
    "PCA_obj.append(PCA(n_components = 3).fit(cubio_1_clean))\n",
    "n_sample = X_train.shape[0]\n",
    "h = 16\n",
    "patches_proj = PCA_obj[0].transform(cubio_1_remov)\n",
    "cubio_pos = patches_proj.reshape(n_sample,h,h,-1)\n",
    "cubio_neg = -cubio_pos\n",
    "cubio_pca = np.concatenate((cubio_pos, cubio_neg), axis=3)\n",
    "dc = cubio_1.mean(axis=1)*2\n",
    "dc = dc.reshape(n_sample, h, h, -1)\n",
    "cubio_next = relu(np.concatenate((cubio_pca, dc), axis=3))\n",
    "feature_list.append(cubio_next)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### the second stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cubio_2 = flatten_patches(cubio, 4)\n",
    "\n",
    "cubio_2_remov = remove_patches_mean(cubio_2)\n",
    "\n",
    "cubio_2_clean = cubio_2_remov\n",
    "\n",
    "PCA_obj = []\n",
    "k.append(PCA_obj)\n",
    "\n",
    "PCA_obj.append(PCA(n_components = 4).fit(cubio_2_clean))\n",
    "h = 8\n",
    "patches_proj = PCA_obj[0].transform(cubio_2_remov)\n",
    "cubio_pos = patches_proj.reshape(n_sample,h,h,-1)\n",
    "cubio_neg = -cubio_pos\n",
    "cubio_pca = np.concatenate((cubio_pos, cubio_neg), axis=3)\n",
    "dc = cubio_2.mean(axis=1)*2\n",
    "dc = dc.reshape(n_sample, h, h, -1)\n",
    "cubio_next = relu(np.concatenate((cubio_pca, dc), axis=3))\n",
    "feature_list.append(cubio_next)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### the third stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cubio_3 = flatten_patches(cubio, 8)\n",
    "\n",
    "cubio_3_remov = remove_patches_mean(cubio_3)\n",
    "\n",
    "cubio_3_clean = cubio_3_remov\n",
    "\n",
    "kmeans = KMeans(n_clusters=3, n_init=3, max_iter=50, verbose=0, random_state=0)\n",
    "kmeans.fit(cubio_3_clean)\n",
    "k_means.append(kmeans)\n",
    "\n",
    "\n",
    "PCA_idx = kmeans.predict(cubio_3_remov)\n",
    "\n",
    "PCA_obj = []\n",
    "cubio_next = np.zeros((PCA_idx.shape[0], 43))\n",
    "k.append(PCA_obj)\n",
    "for cls in range(3):\n",
    "    ind = PCA_idx==cls\n",
    "    cubio_cls = cubio_3_remov[ind,:]\n",
    "    PCA_obj.append(PCA(n_components = 7).fit(cubio_cls))\n",
    "    n_sample = X_train.shape[0]\n",
    "    h = 4\n",
    "    cubio_pos = PCA_obj[cls].transform(cubio_cls)\n",
    "    cubio_neg = -cubio_pos\n",
    "    cubio_pca = np.concatenate((cubio_pos, cubio_neg), axis=1)\n",
    "    cubio_next[ind,cls*14:(cls+1)*14] = cubio_pca\n",
    "    dc = cubio_3[ind,:].mean(axis=1)*2\n",
    "    cubio_next[ind,42] = dc\n",
    "\n",
    "cubio_next = relu(cubio_next.reshape(X_train.shape[0], 4, 4, 43))\n",
    "feature_list.append(cubio_next)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### the fourth stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cubio_4 = flatten_patches(cubio, 16)\n",
    "\n",
    "cubio_4_remov = remove_patches_mean(cubio_4)\n",
    "\n",
    "cubio_4_clean = cubio_4_remov\n",
    "\n",
    "kmeans = KMeans(n_clusters=3, n_init=3, max_iter=50, verbose=0, random_state=0)\n",
    "kmeans.fit(cubio_4_clean)\n",
    "k_means.append(kmeans)\n",
    "\n",
    "\n",
    "PCA_idx = kmeans.predict(cubio_4_remov)\n",
    "\n",
    "PCA_obj = []\n",
    "cubio_next = np.zeros((PCA_idx.shape[0], 37))\n",
    "k.append(PCA_obj)\n",
    "for cls in range(3):\n",
    "    ind = PCA_idx==cls\n",
    "    cubio_cls = cubio_4_remov[ind,:]\n",
    "    PCA_obj.append(PCA(n_components = 6).fit(cubio_cls))\n",
    "    n_sample = X_train.shape[0]\n",
    "    h = 2\n",
    "    cubio_pos = PCA_obj[cls].transform(cubio_cls)\n",
    "    cubio_neg = -cubio_pos\n",
    "    cubio_pca = np.concatenate((cubio_pos, cubio_neg), axis=1)\n",
    "    cubio_next[ind,cls*12:(cls+1)*12] = cubio_pca\n",
    "    dc = cubio_4[ind,:].mean(axis=1)*2\n",
    "    cubio_next[ind,36] = dc\n",
    "\n",
    "cubio_next = relu(cubio_next.reshape(X_train.shape[0], 2, 2, 37))\n",
    "feature_list.append(cubio_next)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the fifth stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "cubio_5 = flatten_patches(cubio, 32)\n",
    "\n",
    "cubio_5_remov = remove_patches_mean(cubio_5)\n",
    "\n",
    "cubio_5_clean = cubio_5_remov\n",
    "\n",
    "kmeans = KMeans(n_clusters=3, n_init=3, max_iter=50, verbose=0, random_state=0)\n",
    "kmeans.fit(cubio_5_clean)\n",
    "k_means.append(kmeans)\n",
    "\n",
    "\n",
    "PCA_idx = kmeans.predict(cubio_5_remov)\n",
    "\n",
    "PCA_obj = []\n",
    "cubio_next = np.zeros((PCA_idx.shape[0], 49))\n",
    "k.append(PCA_obj)\n",
    "for cls in range(3):\n",
    "    ind = PCA_idx==cls\n",
    "    cubio_cls = cubio_5_remov[ind,:]\n",
    "    PCA_obj.append(PCA(n_components = 8).fit(cubio_cls))\n",
    "    n_sample = X_train.shape[0]\n",
    "    h = 1\n",
    "    cubio_pos = PCA_obj[cls].transform(cubio_cls)\n",
    "    cubio_neg = -cubio_pos\n",
    "    cubio_pca = np.concatenate((cubio_pos, cubio_neg), axis=1)\n",
    "    cubio_next[ind,cls*16:(cls+1)*16] = cubio_pca\n",
    "    dc = cubio_5[ind,:].mean(axis=1)*2\n",
    "    cubio_next[ind,48] = dc\n",
    "\n",
    "cubio_next = relu(cubio_next.reshape(X_train.shape[0], 1, 1, 49))\n",
    "feature_list.append(cubio_next)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### fuse the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of features we get is (60000, 3253).\n"
     ]
    }
   ],
   "source": [
    "features = feature_fusion(feature_list, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### machine learning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of feature dimensions passing F-test is 1626.\n",
      "the number of dimensions kept is 32.\n",
      "the number of dimensions kept is 64.\n",
      "the number of dimensions kept is 128.\n",
      "SVM is under training...\n",
      "SVM accuracy on training sample is 0.995267\n",
      "SVM is under training...\n",
      "SVM accuracy on training sample is 0.994050\n",
      "SVM is under training...\n",
      "SVM accuracy on training sample is 0.990600\n"
     ]
    }
   ],
   "source": [
    "#feature selection\n",
    "X_f, Ftest = F_test(50, features, y_train_batch)\n",
    "\n",
    "#feature reduction\n",
    "X_pc_32, pca_32 = Reduce_Feature(32, X_f)\n",
    "X_pc_64, pca_64 = Reduce_Feature(64, X_f)\n",
    "X_pc_128, pca_128 = Reduce_Feature(128, X_f)\n",
    "\n",
    "#SVM training\n",
    "svm_32, accuracy_svm_training_32= SVM_training_v2(X_pc_32, y_train_batch)\n",
    "svm_64, accuracy_svm_training_64= SVM_training_v2(X_pc_64, y_train_batch)\n",
    "svm_128, accuracy_svm_training_128= SVM_training_v2(X_pc_128, y_train_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#preprocess testing image batch and label batch \n",
    "X_test, y_test_batch = image_set_preprocessing(X_test_raw, y_test_raw, batch_ratio = 1)\n",
    "\n",
    "#prepare testing parameters list\n",
    "feature_list_test = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### the first stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cubio_1_test = flatten_patches(X_test, 2)\n",
    "\n",
    "cubio_1_remov_test = remove_patches_mean(cubio_1_test)\n",
    "\n",
    "n_sample = X_test.shape[0]\n",
    "h = 16\n",
    "patches_proj = k[0][0].transform(cubio_1_remov_test)\n",
    "cubio_pos = patches_proj.reshape(n_sample,h,h,-1)\n",
    "cubio_neg = -cubio_pos\n",
    "cubio_pca = np.concatenate((cubio_pos, cubio_neg), axis=3)\n",
    "dc = cubio_1_test.mean(axis=1)*2\n",
    "dc = dc.reshape(n_sample, h, h, -1)\n",
    "cubio_next = relu(np.concatenate((cubio_pca, dc), axis=3))\n",
    "feature_list_test.append(cubio_next)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### the second stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cubio_2_test = flatten_patches(X_test, 4)\n",
    "\n",
    "cubio_2_remov_test = remove_patches_mean(cubio_2_test)\n",
    "\n",
    "h = 8\n",
    "patches_proj = k[1][0].transform(cubio_2_remov_test)\n",
    "cubio_pos = patches_proj.reshape(n_sample,h,h,-1)\n",
    "cubio_neg = -cubio_pos\n",
    "cubio_pca = np.concatenate((cubio_pos, cubio_neg), axis=3)\n",
    "dc = cubio_2_test.mean(axis=1)*2\n",
    "dc = dc.reshape(n_sample, h, h, -1)\n",
    "cubio_next = relu(np.concatenate((cubio_pca, dc), axis=3))\n",
    "feature_list_test.append(cubio_next)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### the third stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cubio_3_test = flatten_patches(X_test, 8)\n",
    "\n",
    "cubio_3_remov_test = remove_patches_mean(cubio_3_test)\n",
    "\n",
    "PCA_idx = k_means[0].predict(cubio_3_remov_test)\n",
    "\n",
    "cubio_next = np.zeros((PCA_idx.shape[0], 43))\n",
    "\n",
    "for cls in range(3):\n",
    "    ind = PCA_idx==cls\n",
    "    cubio_cls_test = cubio_3_remov_test[ind,:]\n",
    "    h = 4\n",
    "    cubio_pos = k[2][cls].transform(cubio_cls_test)\n",
    "    cubio_neg = -cubio_pos\n",
    "    cubio_pca = np.concatenate((cubio_pos, cubio_neg), axis=1)\n",
    "    cubio_next[ind,cls*14:(cls+1)*14] = cubio_pca\n",
    "    dc = cubio_3_test[ind,:].mean(axis=1)*2\n",
    "    cubio_next[ind,42] = dc\n",
    "\n",
    "cubio_next = relu(cubio_next.reshape(n_sample, 4, 4, 43))\n",
    "feature_list_test.append(cubio_next)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### the fourth stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cubio_4_test = flatten_patches(X_test, 16)\n",
    "\n",
    "cubio_4_remov_test = remove_patches_mean(cubio_4_test)\n",
    "\n",
    "PCA_idx = k_means[1].predict(cubio_4_remov_test)\n",
    "\n",
    "cubio_next = np.zeros((PCA_idx.shape[0], 37))\n",
    "\n",
    "for cls in range(3):\n",
    "    ind = PCA_idx==cls\n",
    "    cubio_cls = cubio_4_remov_test[ind,:]\n",
    "    h = 2\n",
    "    cubio_pos = k[3][cls].transform(cubio_cls)\n",
    "    cubio_neg = -cubio_pos\n",
    "    cubio_pca = np.concatenate((cubio_pos, cubio_neg), axis=1)\n",
    "    cubio_next[ind,cls*12:(cls+1)*12] = cubio_pca\n",
    "    dc = cubio_4_test[ind,:].mean(axis=1)*2\n",
    "    cubio_next[ind,36] = dc\n",
    "\n",
    "cubio_next = relu(cubio_next.reshape(n_sample, 2, 2, 37))\n",
    "feature_list_test.append(cubio_next)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the fifth stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "cubio_5_test = flatten_patches(X_test, 32)\n",
    "\n",
    "cubio_5_remov_test = remove_patches_mean(cubio_5_test)\n",
    "\n",
    "PCA_idx = k_means[2].predict(cubio_5_remov_test)\n",
    "\n",
    "cubio_next = np.zeros((PCA_idx.shape[0], 49))\n",
    "\n",
    "for cls in range(3):\n",
    "    ind = PCA_idx==cls\n",
    "    cubio_cls = cubio_5_remov_test[ind,:]\n",
    "    h = 1\n",
    "    cubio_pos = k[4][cls].transform(cubio_cls)\n",
    "    cubio_neg = -cubio_pos\n",
    "    cubio_pca = np.concatenate((cubio_pos, cubio_neg), axis=1)\n",
    "    cubio_next[ind,cls*16:(cls+1)*16] = cubio_pca\n",
    "    dc = cubio_5_test[ind,:].mean(axis=1)*2\n",
    "    cubio_next[ind,48] = dc\n",
    "\n",
    "cubio_next = relu(cubio_next.reshape(n_sample, 1, 1, 49))\n",
    "feature_list_test.append(cubio_next)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fuse  the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of features we get is (10000, 3253).\n"
     ]
    }
   ],
   "source": [
    "features_test = feature_fusion(feature_list_test, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### classifying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test smaples are under SVM's testing...\n",
      "the number of feature dimensions passing F-test is 1626.\n",
      "the number of dimensions kept is 32.\n",
      "SVM accuracy on test sample is 0.979900\n",
      "Test smaples are under SVM's testing...\n",
      "the number of feature dimensions passing F-test is 1626.\n",
      "the number of dimensions kept is 64.\n",
      "SVM accuracy on test sample is 0.981800\n",
      "Test smaples are under SVM's testing...\n",
      "the number of feature dimensions passing F-test is 1626.\n",
      "the number of dimensions kept is 128.\n",
      "SVM accuracy on test sample is 0.981300\n"
     ]
    }
   ],
   "source": [
    "#F-test --> PCA reducing dims --> SVM testing\n",
    "accuracy_svm_testing_32, y_pred_svm_32 = SVM_testing(features_test, y_test_batch, Ftest, pca_32, svm_32)\n",
    "accuracy_svm_testing_64, y_pred_svm_64 = SVM_testing(features_test, y_test_batch, Ftest, pca_64, svm_64)\n",
    "accuracy_svm_testing_128, y_pred_svm_128 = SVM_testing(features_test, y_test_batch, Ftest, pca_128, svm_128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The second version -- tree structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Training process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#prepare training parameters list\n",
    "k = []\n",
    "k_means = []\n",
    "\n",
    "feature_list = []\n",
    "n_comps = [3, 4, 7, 6, 8]\n",
    "\n",
    "#preprocess input image batch and label batch\n",
    "X_train, y_train_batch = image_set_preprocessing(X_train_raw, y_train_raw, batch_ratio = 1)\n",
    "cubio = copy.deepcopy(X_train)\n",
    "\n",
    "#compute the number of layers\n",
    "layer_cnt = (int)(log(X_train.shape[1])/log(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### the first stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cubio_1 = flatten_patches_v2(cubio)\n",
    "\n",
    "cubio_1_remov = remove_patches_mean(cubio_1)\n",
    "\n",
    "cubio_1_clean = remove_low_variance(cubio_1_remov,thr=0.05)\n",
    "\n",
    "PCA_obj = []\n",
    "k.append(PCA_obj)\n",
    "\n",
    "PCA_obj.append(PCA(n_components = 3).fit(cubio_1_clean))\n",
    "n_sample = X_train.shape[0]\n",
    "h = 16\n",
    "patches_proj = PCA_obj[0].transform(cubio_1_remov)\n",
    "cubio_pos = patches_proj.reshape(n_sample,h,h,-1)\n",
    "cubio_neg = -cubio_pos\n",
    "cubio_pca = np.concatenate((cubio_pos, cubio_neg), axis=3)\n",
    "dc = cubio_1.mean(axis=1)*2\n",
    "dc = dc.reshape(n_sample, h, h, -1)\n",
    "cubio_next = relu(np.concatenate((cubio_pca, dc), axis=3))\n",
    "feature_list.append(cubio_next)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### the second stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cubio_2 = flatten_patches_v2(cubio_next)\n",
    "\n",
    "cubio_2_remov = remove_patches_mean(cubio_2)\n",
    "\n",
    "cubio_2_clean = cubio_2_remov\n",
    "\n",
    "PCA_obj = []\n",
    "k.append(PCA_obj)\n",
    "\n",
    "PCA_obj.append(PCA(n_components = 4).fit(cubio_2_clean))\n",
    "h = 8\n",
    "patches_proj = PCA_obj[0].transform(cubio_2_remov)\n",
    "cubio_pos = patches_proj.reshape(n_sample,h,h,-1)\n",
    "cubio_neg = -cubio_pos\n",
    "cubio_pca = np.concatenate((cubio_pos, cubio_neg), axis=3)\n",
    "dc = cubio_2.mean(axis=1)*2\n",
    "dc = dc.reshape(n_sample, h, h, -1)\n",
    "cubio_next = relu(np.concatenate((cubio_pca, dc), axis=3))\n",
    "feature_list.append(cubio_next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 8, 8, 9)"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cubio_next.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### the third stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cubio_3 = flatten_patches_v2(cubio_next)\n",
    "\n",
    "cubio_3_remov = remove_patches_mean(cubio_3)\n",
    "\n",
    "cubio_3_clean = cubio_3_remov\n",
    "\n",
    "kmeans = KMeans(n_clusters=3, n_init=3, max_iter=50, verbose=0, random_state=0)\n",
    "kmeans.fit(cubio_3_clean)\n",
    "k_means.append(kmeans)\n",
    "\n",
    "PCA_idx = kmeans.predict(cubio_3_remov)\n",
    "\n",
    "PCA_obj = []\n",
    "cubio_next = np.zeros((PCA_idx.shape[0], 43))\n",
    "k.append(PCA_obj)\n",
    "for cls in range(3):\n",
    "    ind = PCA_idx==cls\n",
    "    cubio_cls = cubio_3_remov[ind,:]\n",
    "    PCA_obj.append(PCA(n_components = 7).fit(cubio_cls))\n",
    "    n_sample = X_train.shape[0]\n",
    "    h = 4\n",
    "    cubio_pos = PCA_obj[cls].transform(cubio_cls)\n",
    "    cubio_neg = -cubio_pos\n",
    "    cubio_pca = np.concatenate((cubio_pos, cubio_neg), axis=1)\n",
    "    cubio_next[ind,cls*14:(cls+1)*14] = cubio_pca\n",
    "    dc = cubio_3[ind,:].mean(axis=1)*2\n",
    "    cubio_next[ind,42] = dc\n",
    "\n",
    "cubio_next = relu(cubio_next.reshape(X_train.shape[0], 4, 4, 43))\n",
    "feature_list.append(cubio_next)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### the fourth stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cubio_4 = flatten_patches_v2(cubio_next)\n",
    "\n",
    "cubio_4_remov = remove_patches_mean(cubio_4)\n",
    "\n",
    "cubio_4_clean = cubio_4_remov\n",
    "\n",
    "kmeans = KMeans(n_clusters=3, n_init=3, max_iter=50, verbose=0, random_state=0)\n",
    "kmeans.fit(cubio_4_clean)\n",
    "k_means.append(kmeans)\n",
    "\n",
    "\n",
    "PCA_idx = kmeans.predict(cubio_4_remov)\n",
    "\n",
    "PCA_obj = []\n",
    "cubio_next = np.zeros((PCA_idx.shape[0], 37))\n",
    "k.append(PCA_obj)\n",
    "for cls in range(3):\n",
    "    ind = PCA_idx==cls\n",
    "    cubio_cls = cubio_4_remov[ind,:]\n",
    "    PCA_obj.append(PCA(n_components = 6).fit(cubio_cls))\n",
    "    n_sample = X_train.shape[0]\n",
    "    h = 2\n",
    "    cubio_pos = PCA_obj[cls].transform(cubio_cls)\n",
    "    cubio_neg = -cubio_pos\n",
    "    cubio_pca = np.concatenate((cubio_pos, cubio_neg), axis=1)\n",
    "    cubio_next[ind,cls*12:(cls+1)*12] = cubio_pca\n",
    "    dc = cubio_4[ind,:].mean(axis=1)*2\n",
    "    cubio_next[ind,36] = dc\n",
    "\n",
    "cubio_next = relu(cubio_next.reshape(X_train.shape[0], 2, 2, 37))\n",
    "feature_list.append(cubio_next)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### the fifth stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cubio_5 = flatten_patches_v2(cubio_next)\n",
    "\n",
    "cubio_5_remov = remove_patches_mean(cubio_5)\n",
    "\n",
    "cubio_5_clean = cubio_5_remov\n",
    "\n",
    "kmeans = KMeans(n_clusters=3, n_init=3, max_iter=50, verbose=0, random_state=0)\n",
    "kmeans.fit(cubio_5_clean)\n",
    "k_means.append(kmeans)\n",
    "\n",
    "\n",
    "PCA_idx = kmeans.predict(cubio_5_remov)\n",
    "\n",
    "PCA_obj = []\n",
    "cubio_next = np.zeros((PCA_idx.shape[0], 49))\n",
    "k.append(PCA_obj)\n",
    "for cls in range(3):\n",
    "    ind = PCA_idx==cls\n",
    "    cubio_cls = cubio_5_remov[ind,:]\n",
    "    PCA_obj.append(PCA(n_components = 8).fit(cubio_cls))\n",
    "    n_sample = X_train.shape[0]\n",
    "    h = 1\n",
    "    cubio_pos = PCA_obj[cls].transform(cubio_cls)\n",
    "    cubio_neg = -cubio_pos\n",
    "    cubio_pca = np.concatenate((cubio_pos, cubio_neg), axis=1)\n",
    "    cubio_next[ind,cls*16:(cls+1)*16] = cubio_pca\n",
    "    dc = cubio_5[ind,:].mean(axis=1)*2\n",
    "    cubio_next[ind,48] = dc\n",
    "\n",
    "cubio_next = relu(cubio_next.reshape(X_train.shape[0], 1, 1, 49))\n",
    "feature_list.append(cubio_next)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### fuse the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of features we get is (60000, 3253).\n"
     ]
    }
   ],
   "source": [
    "features = feature_fusion(feature_list, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### machine learning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of feature dimensions passing F-test is 1626.\n",
      "the number of dimensions kept is 32.\n",
      "the number of dimensions kept is 64.\n",
      "the number of dimensions kept is 128.\n",
      "SVM is under training...\n",
      "SVM accuracy on training sample is 0.994650\n",
      "SVM is under training...\n",
      "SVM accuracy on training sample is 0.993083\n",
      "SVM is under training...\n",
      "SVM accuracy on training sample is 0.988700\n"
     ]
    }
   ],
   "source": [
    "#feature selection\n",
    "X_f, Ftest = F_test(50, features, y_train_batch)\n",
    "\n",
    "#feature reduction\n",
    "X_pc_32, pca_32 = Reduce_Feature(32, X_f)\n",
    "X_pc_64, pca_64 = Reduce_Feature(64, X_f)\n",
    "X_pc_128, pca_128 = Reduce_Feature(128, X_f)\n",
    "\n",
    "#SVM training\n",
    "svm_32, accuracy_svm_training_32= SVM_training_v2(X_pc_32, y_train_batch)\n",
    "svm_64, accuracy_svm_training_64= SVM_training_v2(X_pc_64, y_train_batch)\n",
    "svm_128, accuracy_svm_training_128= SVM_training_v2(X_pc_128, y_train_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#preprocess testing image batch and label batch \n",
    "X_test, y_test_batch = image_set_preprocessing(X_test_raw, y_test_raw, batch_ratio = 1)\n",
    "cubio = copy.deepcopy(X_test)\n",
    "\n",
    "#prepare testing parameters list\n",
    "feature_list_test = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### the first stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cubio_1_test = flatten_patches_v2(cubio)\n",
    "\n",
    "cubio_1_remov_test = remove_patches_mean(cubio_1_test)\n",
    "\n",
    "n_sample = X_test.shape[0]\n",
    "h = 16\n",
    "patches_proj = k[0][0].transform(cubio_1_remov_test)\n",
    "cubio_pos = patches_proj.reshape(n_sample,h,h,-1)\n",
    "cubio_neg = -cubio_pos\n",
    "cubio_pca = np.concatenate((cubio_pos, cubio_neg), axis=3)\n",
    "dc = cubio_1_test.mean(axis=1)*2\n",
    "dc = dc.reshape(n_sample, h, h, -1)\n",
    "cubio_next = relu(np.concatenate((cubio_pca, dc), axis=3))\n",
    "feature_list_test.append(cubio_next)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### the second stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cubio_2_test = flatten_patches_v2(cubio_next)\n",
    "\n",
    "cubio_2_remov_test = remove_patches_mean(cubio_2_test)\n",
    "\n",
    "h = 8\n",
    "patches_proj = k[1][0].transform(cubio_2_remov_test)\n",
    "cubio_pos = patches_proj.reshape(n_sample,h,h,-1)\n",
    "cubio_neg = -cubio_pos\n",
    "cubio_pca = np.concatenate((cubio_pos, cubio_neg), axis=3)\n",
    "dc = cubio_2_test.mean(axis=1)*2\n",
    "dc = dc.reshape(n_sample, h, h, -1)\n",
    "cubio_next = relu(np.concatenate((cubio_pca, dc), axis=3))\n",
    "feature_list_test.append(cubio_next)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### the third stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cubio_3_test = flatten_patches_v2(cubio_next)\n",
    "\n",
    "cubio_3_remov_test = remove_patches_mean(cubio_3_test)\n",
    "\n",
    "PCA_idx = k_means[0].predict(cubio_3_remov_test)\n",
    "\n",
    "cubio_next = np.zeros((PCA_idx.shape[0], 43))\n",
    "\n",
    "for cls in range(3):\n",
    "    ind = PCA_idx==cls\n",
    "    cubio_cls_test = cubio_3_remov_test[ind,:]\n",
    "    h = 4\n",
    "    cubio_pos = k[2][cls].transform(cubio_cls_test)\n",
    "    cubio_neg = -cubio_pos\n",
    "    cubio_pca = np.concatenate((cubio_pos, cubio_neg), axis=1)\n",
    "    cubio_next[ind,cls*14:(cls+1)*14] = cubio_pca\n",
    "    dc = cubio_3_test[ind,:].mean(axis=1)*2\n",
    "    cubio_next[ind,42] = dc\n",
    "\n",
    "cubio_next = relu(cubio_next.reshape(n_sample, 4, 4, 43))\n",
    "feature_list_test.append(cubio_next)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### the fourth stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cubio_4_test = flatten_patches_v2(cubio_next)\n",
    "\n",
    "cubio_4_remov_test = remove_patches_mean(cubio_4_test)\n",
    "\n",
    "PCA_idx = k_means[1].predict(cubio_4_remov_test)\n",
    "\n",
    "cubio_next = np.zeros((PCA_idx.shape[0], 37))\n",
    "\n",
    "for cls in range(3):\n",
    "    ind = PCA_idx==cls\n",
    "    cubio_cls = cubio_4_remov_test[ind,:]\n",
    "    h = 2\n",
    "    cubio_pos = k[3][cls].transform(cubio_cls)\n",
    "    cubio_neg = -cubio_pos\n",
    "    cubio_pca = np.concatenate((cubio_pos, cubio_neg), axis=1)\n",
    "    cubio_next[ind,cls*12:(cls+1)*12] = cubio_pca\n",
    "    dc = cubio_4_test[ind,:].mean(axis=1)*2\n",
    "    cubio_next[ind,36] = dc\n",
    "\n",
    "cubio_next = relu(cubio_next.reshape(n_sample, 2, 2, 37))\n",
    "feature_list_test.append(cubio_next)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the fifth stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "cubio_5_test = flatten_patches_v2(cubio_next)\n",
    "\n",
    "cubio_5_remov_test = remove_patches_mean(cubio_5_test)\n",
    "\n",
    "PCA_idx = k_means[2].predict(cubio_5_remov_test)\n",
    "\n",
    "cubio_next = np.zeros((PCA_idx.shape[0], 49))\n",
    "\n",
    "for cls in range(3):\n",
    "    ind = PCA_idx==cls\n",
    "    cubio_cls = cubio_5_remov_test[ind,:]\n",
    "    h = 1\n",
    "    cubio_pos = k[4][cls].transform(cubio_cls)\n",
    "    cubio_neg = -cubio_pos\n",
    "    cubio_pca = np.concatenate((cubio_pos, cubio_neg), axis=1)\n",
    "    cubio_next[ind,cls*16:(cls+1)*16] = cubio_pca\n",
    "    dc = cubio_5_test[ind,:].mean(axis=1)*2\n",
    "    cubio_next[ind,48] = dc\n",
    "\n",
    "cubio_next = relu(cubio_next.reshape(n_sample, 1, 1, 49))\n",
    "feature_list_test.append(cubio_next)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fuse the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of features we get is (10000, 3253).\n"
     ]
    }
   ],
   "source": [
    "features_test = feature_fusion(feature_list_test, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### classifying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test smaples are under SVM's testing...\n",
      "the number of feature dimensions passing F-test is 1626.\n",
      "the number of dimensions kept is 32.\n",
      "SVM accuracy on test sample is 0.980800\n",
      "Test smaples are under SVM's testing...\n",
      "the number of feature dimensions passing F-test is 1626.\n",
      "the number of dimensions kept is 64.\n",
      "SVM accuracy on test sample is 0.981600\n",
      "Test smaples are under SVM's testing...\n",
      "the number of feature dimensions passing F-test is 1626.\n",
      "the number of dimensions kept is 128.\n",
      "SVM accuracy on test sample is 0.978900\n"
     ]
    }
   ],
   "source": [
    "#F-test --> PCA reducing dims --> SVM testing\n",
    "accuracy_svm_testing_32, y_pred_svm_32 = SVM_testing(features_test, y_test_batch, Ftest, pca_32, svm_32)\n",
    "accuracy_svm_testing_64, y_pred_svm_64 = SVM_testing(features_test, y_test_batch, Ftest, pca_64, svm_64)\n",
    "accuracy_svm_testing_128, y_pred_svm_128 = SVM_testing(features_test, y_test_batch, Ftest, pca_128, svm_128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
